{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy a DecisionTree model using Azure ML Python SDK "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle to the workspace\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "\r\n",
        "# Authentication package\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "\r\n",
        "credential = DefaultAzureCredential()\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "#verify workspace details \r\n",
        "workspace = Workspace.from_config()\r\n",
        "print(  \"Workspace name: \" + workspace.name,\r\n",
        "        \"Workspace region: \" + workspace.location,\r\n",
        "        \"Subscription id: \" + workspace.subscription_id,\r\n",
        "        \"Resource group: \" + workspace.resource_group, sep=\"\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: ws001\nWorkspace region: eastus\nSubscription id: eb1308d1-6004-4e62-aebb-ec8032a938d0\nResource group: ml\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1681564632137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to the workspace\r\n",
        "ml_client = MLClient(\r\n",
        "    credential=credential,\r\n",
        "    subscription_id=workspace.subscription_id,\r\n",
        "    resource_group_name=workspace.resource_group,\r\n",
        "    workspace_name=workspace.name,\r\n",
        ")\r\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f23b0f648e0>,\n         subscription_id=eb1308d1-6004-4e62-aebb-ec8032a938d0,\n         resource_group_name=ml,\n         workspace_name=ws001)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564636901
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating compoute cluster resource and connect it with the current workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "# Name assigned to the compute cluster\r\n",
        "cpu_compute_target = \"CC00\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # let's see if the compute target already exists\r\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\r\n",
        "    print(\r\n",
        "        f\"Compute resource {cpu_compute_target} already existed under compute cluster tab.\"\r\n",
        "    )\r\n",
        "\r\n",
        "except Exception:\r\n",
        "    print(\"Initializing new computer cluster\")\r\n",
        "\r\n",
        "    # Let's create the Azure ML compute object with the intended parameters\r\n",
        "    cpu_cluster = AmlCompute(\r\n",
        "        name=cpu_compute_target,\r\n",
        "        type=\"amlcompute\",\r\n",
        "        size=\"STANDARD_F4S_V2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=2,\r\n",
        "        idle_time_before_scale_down=180,\r\n",
        "        tier=\"Dedicated\",\r\n",
        "    )\r\n",
        "    print(\r\n",
        "        f\"Compute resource with name {cpu_cluster.name} will be created, using instance {cpu_cluster.size}\"\r\n",
        "    )\r\n",
        "    \r\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You already have a cluster named CC00, we'll reuse it as is.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564640822
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# The default datastore is a blob storage container where datasets are stored\r\n",
        "datastore = workspace.get_default_datastore()\r\n",
        "\r\n",
        "# Load some data into a dataframe (Note: Pandas is just one path into Azure ML)\r\n",
        "df = pd.read_csv('./heart.csv')\r\n",
        "\r\n",
        "# Register the dataset\r\n",
        "ds = Dataset.Tabular.register_pandas_dataframe(\r\n",
        "        dataframe=df, \r\n",
        "        name='Heart_dataset', \r\n",
        "        description='The dataset for cardiovascular diseases prediction',\r\n",
        "        target=datastore\r\n",
        "    )\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Message: rslex failed, falling back to clex.\nPayload: {\"pid\": 9870, \"source\": \"azureml.dataprep\", \"version\": \"4.9.5\", \"trace\": \"azureml|data|dataset_factory.py, line 655 in function register_pandas_dataframe.\\nazureml|data|_loggerfactory.py, line 132 in function wrapper.\\ntmp|ipykernel_9870|3551696286.py, line 11 in function <module>.\", \"subscription\": \"\", \"run_id\": \"\", \"resource_group\": \"\", \"workspace_name\": \"\", \"experiment_id\": \"\", \"location\": \"\", \"rslex_version\": \"2.16.4\"}\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\nFailed to extract subscription information, Exception=AttributeError; 'Logger' object has no attribute 'activity_info'\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564703362
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating environment for Model training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "dependencies_dir = \"./dependencies\"\r\n",
        "os.makedirs(dependencies_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564706554
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {dependencies_dir}/conda.yml\r\n",
        "name: model-env\r\n",
        "channels:\r\n",
        "  - conda-forge\r\n",
        "dependencies:\r\n",
        "  - python=3.8\r\n",
        "  - numpy=1.21.2\r\n",
        "  - pip=21.2.4\r\n",
        "  - scikit-learn=0.24.2\r\n",
        "  - scipy=1.7.1\r\n",
        "  - pandas>=1.1,<1.2\r\n",
        "  - pip:\r\n",
        "    - inference-schema[numpy-support]==1.3.0\r\n",
        "    - xlrd==2.0.1\r\n",
        "    - mlflow== 1.26.1\r\n",
        "    - azureml-mlflow==1.42.0\r\n",
        "    - psutil>=5.8,<5.9\r\n",
        "    - tqdm>=4.59,<4.60\r\n",
        "    - ipykernel~=6.0\r\n",
        "    - matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./dependencies/conda.yml\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\r\n",
        "\r\n",
        "custom_env_name = \"aml-scikit-learn\"\r\n",
        "\r\n",
        "pipeline_job_env = Environment(\r\n",
        "    name=custom_env_name,\r\n",
        "    description=\"Custom environment for Heart Defaults pipeline\",\r\n",
        "    tags={\"scikit-learn\": \"0.24.2\"},\r\n",
        "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\r\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\r\n",
        ")\r\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\r\n",
        "\r\n",
        "print(\r\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name aml-scikit-learn is registered to workspace, the environment version is 3\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564714023
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Training Script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "train_src_dir = \"./src\"\r\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681564721862
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {train_src_dir}/main.py\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def main():\r\n",
        "    \"\"\"Main function of the script.\"\"\"\r\n",
        "\r\n",
        "    # input and output arguments\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\r\n",
        "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\r\n",
        "    parser.add_argument(\"--learning_rate\", required=False, default=0.2, type=float)\r\n",
        "    parser.add_argument(\"--max_depth\", required=False, default=6, type=float)\r\n",
        "    parser.add_argument(\"--min_samples_leaf\", required=False, default=2, type=int)\r\n",
        "    parser.add_argument(\"--random_state\", required=False, default=42, type=int)\r\n",
        "    parser.add_argument(\"--max_leaf_nodes\", required=False, default=6, type=int)\r\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\r\n",
        "    args = parser.parse_args()\r\n",
        "   \r\n",
        "    # Start Logging\r\n",
        "    mlflow.start_run()\r\n",
        "\r\n",
        "    # enable autologging\r\n",
        "    mlflow.sklearn.autolog()\r\n",
        "\r\n",
        "    ###################\r\n",
        "    #<prepare the data>\r\n",
        "    ###################\r\n",
        "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\r\n",
        "\r\n",
        "    print(\"input data:\", args.data)\r\n",
        "    \r\n",
        "    # heart_df = pd.read_csv(args.data, header=1, index_col=0)\r\n",
        "    heart_df = pd.read_csv(\"heart.csv\")\r\n",
        "    print(heart_df.head())\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    heart_df.drop(\"target\", axis=1), heart_df[\"target\"], test_size=0.3\r\n",
        "    )\r\n",
        "    ####################\r\n",
        "    #</prepare the data>\r\n",
        "    ####################\r\n",
        "\r\n",
        "    ##################\r\n",
        "    #<train the model>\r\n",
        "    ##################\r\n",
        "\r\n",
        "    dtc = DecisionTreeClassifier(\r\n",
        "        max_depth=args.max_depth,\r\n",
        "        min_samples_leaf= args.min_samples_leaf,\r\n",
        "        random_state= args.random_state,\r\n",
        "        max_leaf_nodes= args.max_leaf_nodes,\r\n",
        "        \r\n",
        "    )\r\n",
        "    dtc.fit(X_train, y_train)\r\n",
        "\r\n",
        "    y_pred = dtc.predict(X_test)\r\n",
        "\r\n",
        "    print(classification_report(y_test, y_pred))\r\n",
        "    ###################\r\n",
        "    #</train the model>\r\n",
        "    ###################\r\n",
        "\r\n",
        "    ##########################\r\n",
        "    #<save and register model>\r\n",
        "    ##########################\r\n",
        "    # Registering the model to the workspace\r\n",
        "    print(\"Registering the model via MLFlow\")\r\n",
        "    mlflow.sklearn.log_model(\r\n",
        "        sk_model=dtc,\r\n",
        "        registered_model_name=args.registered_model_name,\r\n",
        "        artifact_path=args.registered_model_name,\r\n",
        "    )\r\n",
        "\r\n",
        "    # Saving the model to a file\r\n",
        "    mlflow.sklearn.save_model(\r\n",
        "        sk_model=dtc,\r\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\r\n",
        "    )\r\n",
        "    ###########################\r\n",
        "    #</save and register model>\r\n",
        "    ###########################\r\n",
        "    \r\n",
        "    # Stop Logging\r\n",
        "    mlflow.end_run()\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/main.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create command and input\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\r\n",
        "from azure.ai.ml import Input\r\n",
        "\r\n",
        "registered_model_name = \"heart_defaults_model\"\r\n",
        "\r\n",
        "job = command(\r\n",
        "    inputs=dict(\r\n",
        "        data=\"./heart.csv\", #we already had the file locally so just put the path directory from src\r\n",
        "        test_train_ratio=0.2,\r\n",
        "        learning_rate=0.25,\r\n",
        "        registered_model_name=registered_model_name,\r\n",
        "    ),\r\n",
        "    code=\"./src/\",  # location of source code\r\n",
        "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\r\n",
        "    environment=\"aml-scikit-learn@latest\",\r\n",
        "    compute=\"CC00\",\r\n",
        "    experiment_name=\"train_model_heart_default_prediction\",\r\n",
        "    display_name=\"heart_default_prediction\",\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681565911550
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit job\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the initially created workspace hanlder (ml_client) and the above job, we can submit our model training:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.create_or_update(job)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681565919571
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\r\n",
        "!!! MAKE SURE THE ABOVE JOB IS COMPLETED BEFORE PROCCEEDING TO NEXT STEP\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an online endpoint\r\n",
        "\r\n",
        "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create online endpoint\r\n",
        "\r\n",
        "import uuid\r\n",
        "\r\n",
        "# Making the endpoint name unique\r\n",
        "online_endpoint_name = \"heart-endpoint-\" + str(uuid.uuid4())[:8]"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681566094427
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import (\r\n",
        "    ManagedOnlineEndpoint,\r\n",
        "    ManagedOnlineDeployment,\r\n",
        "    Model,\r\n",
        "    Environment,\r\n",
        ")\r\n",
        "\r\n",
        "# Initiate new online endpoint\r\n",
        "endpoint = ManagedOnlineEndpoint(\r\n",
        "    name=online_endpoint_name,\r\n",
        "    description=\"this is an online endpoint\",\r\n",
        "    auth_mode=\"key\",\r\n",
        "    tags={\r\n",
        "        \"training_dataset\": \"heart_defaults\",\r\n",
        "        \"model_type\": \"sklearn.DecisionTreeClassifier\",\r\n",
        "    },\r\n",
        ")\r\n",
        "\r\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\r\n",
        "\r\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint heart-endpoint-e53a2e5b provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681566195885
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\r\n",
        "!!! THE ENDPOINT CREATION MAY TAKE 6-8 MINUTES\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Verify the endpoint created\r\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\r\n",
        "\r\n",
        "print(\r\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint \"heart-endpoint-e53a2e5b\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681566202314
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy model to the created endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check latest version of the model\r\n",
        "latest_model_version = max(\r\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\r\n",
        ")\r\n",
        "\r\n",
        "# Pick latest model version\r\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\r\n",
        "\r\n",
        "# online deployment.\r\n",
        "blue_deployment = ManagedOnlineDeployment(\r\n",
        "    name=\"blue\",\r\n",
        "    endpoint_name=online_endpoint_name,\r\n",
        "    model=model,\r\n",
        "    instance_type=\"STANDARD_F4S_V2\",\r\n",
        "    instance_count=1,\r\n",
        ")\r\n",
        "\r\n",
        "blue_deployment_results = ml_client.online_deployments.begin_create_or_update(blue_deployment).result()\r\n",
        "\r\n",
        "print(\r\n",
        "    f\"Deployment {blue_deployment_results.name} provisioning state: {blue_deployment_results.provisioning_state}\"\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint heart-endpoint-e53a2e5b exists\ndata_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "........................................................................................."
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681566236520
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up resources\r\n",
        "If you're not going to use the endpoint, delete it to stop using the resource. Make sure no other deployments are using an endpoint before you delete it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}